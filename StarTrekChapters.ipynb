{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas varias de preparación\n",
    "(celda oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:27.325758Z",
     "start_time": "2020-07-12T21:21:27.316810Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# estos son los temas que están disponibles\\n    onedork\\n    grade3\\n    oceans16\\n    chesterish\\n    monokai\\n    solarizedl\\n    solarizedd\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#esto lo tuve que correr en la consola\n",
    "#!conda install jupyterthemes\n",
    "#!jt -t chesterish\n",
    "\n",
    "'''\n",
    "# estos son los temas que están disponibles\n",
    "    onedork\n",
    "    grade3\n",
    "    oceans16\n",
    "    chesterish\n",
    "    monokai\n",
    "    solarizedl\n",
    "    solarizedd\n",
    "\n",
    "'''\n",
    "\n",
    "#!apt-get -qq install -y urlli\n",
    "#!python3 -m spacy download en_core_web_lg\n",
    "#!pip install  textacy\n",
    "#!conda install -c conda-forge spacy-model-en_core_web_lg \n",
    "#!pip uninstall  spacy\n",
    "#después de instalar spacy fue necesario reinstalar jupiter en el ambiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:10:16.491088Z",
     "start_time": "2020-07-12T17:10:16.480117Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pcq8IQAe2T_b"
   },
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:04.106530Z",
     "start_time": "2020-07-12T21:21:27.328033Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EZ6cYJOt7LvP"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import sys\n",
    "#para hacer nlp\n",
    "import spacy\n",
    "import textacy.extract\n",
    "\n",
    "# tuve que correr el siguiente comando para instalar la version lg (826 MB)\n",
    "#!python3 -m spacy download en_core_web_lg\n",
    "# sino tenía que ejecutar nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp2 = spacy.load('en_core_web_lg')\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:10:34.867633Z",
     "start_time": "2020-07-12T17:10:18.915524Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "DYyzmsvyCOFX",
    "outputId": "876a21bb-e5a6-4bd9-9f30-b55b772eb6d5"
   },
   "source": [
    "# Carga de contenido de capítulos de Star Trek\n",
    "## web scrapping y parseo\n",
    "\n",
    "- Paso 1: obtener todos los links de los capítulos de la serie\n",
    "\n",
    "\n",
    " Ejemplos seguidos\n",
    "- - https://scipython.com/blog/scraping-a-wikipedia-table-with-beautiful-soup/\n",
    "- - https://towardsdatascience.com/how-to-web-scrape-with-python-in-4-minutes-bc49186a8460\n",
    "- - https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- no fue necesario, pero tener en cuenta urljoin(url_base ,a.get('href'))\n",
    "\n",
    "\n",
    "Paso 2: obtener todos los plot de los capítulos de la serie\n",
    "- esto es para tomar el contenido del plot cuando ya estoy en la página del capítulo\n",
    "- como explícitamente quiero haer lenta la iteración de las páginas para asignar el plot, itero a mano por el índice (pendiente)\n",
    "- Se limpia el contenido html y se deja solamente el texto usando BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.483208Z",
     "start_time": "2020-07-12T21:22:04.117503Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "d80QJNnjGgX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guardado plot 0\n",
      "guardado plot 1\n",
      "guardado plot 2\n",
      "guardado plot 3\n",
      "guardado plot 4\n",
      "guardado plot 5\n",
      "Fin de carga de plots\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the URL you want to webscrape from\n",
    "url_base = 'https://en.wikipedia.org/wiki/List_of_Star_Trek:_The_Original_Series_episodes'\n",
    "# Connect to the URL\n",
    "response = requests.get(url_base)\n",
    "# Parse HTML and save to BeautifulSoup object¶\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# Paso 1: obtener todos los links de los capítulos de la serie\n",
    "# Ejemplos seguidos\n",
    "# https://scipython.com/blog/scraping-a-wikipedia-table-with-beautiful-soup/\n",
    "# https://towardsdatascience.com/how-to-web-scrape-with-python-in-4-minutes-bc49186a8460\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# no fue necesario, pero tener en cuenta urljoin(url_base ,a.get('href'))\n",
    "# BORRAR LA LÍNEA QUE CONFIGURA UN MÁXIMO DE LINKS\n",
    "\n",
    "\n",
    "#guardo el nro de capitulo en la serie y el absoluto, el título del capítulo y el link correspondiente\n",
    "columns_df = ['No.overall', 'No. inseason', 'Title', 'Stardate', 'Link']\n",
    "chapters_link = pd.DataFrame(columns=columns_df)\n",
    "\n",
    "#itero sobre todas las tablas de la página filtrando por class\n",
    "#BORRAR LUEGO, ESTO ES PARA DESA\n",
    "seasonsCount=0\n",
    "maxSeasons = 2\n",
    "maxChapters=6\n",
    "for table in soup.findAll('table', attrs={'class':'wikitable plainrowheaders wikiepisodetable'}):\n",
    "    #BORRAR LUEGO, ESTO ES PARA DESA\n",
    "    if seasonsCount<maxSeasons:\n",
    "      \n",
    "      seasonsCount +=1\n",
    "      ths = table.find_all('th')\n",
    "      headings = [th.text.strip() for th in ths]\n",
    "            \n",
    "      # verifico si es del tipo de tabla que me interesa\n",
    "      if headings[:3] == ['No.overall', 'No. inseason', 'Title']:\n",
    "        #para topear la cantidad de links por temporada\n",
    "        chapters_count = 0\n",
    "        for row in table.tbody.findAll('tr'):\n",
    "          #\n",
    "          if chapters_count <= maxChapters :\n",
    "            chapters_count +=1\n",
    "            try:\n",
    "              nooverall = row.findAll('th')[0].string\n",
    "              noinseason = row.findAll('td')[0].string\n",
    "              title = row.findAll('td')[1].find('a').string\n",
    "              stardate = row.findAll('td')[2].string\n",
    "              link = urljoin(url_base ,row.findAll('td')[1].find('a').get('href'))\n",
    "              \n",
    "                        \n",
    "              chapters_link = chapters_link.\\\n",
    "                            append(\\\n",
    "                                    pd.DataFrame([[nooverall, noinseason, title, stardate, link]], \\\n",
    "                                    columns=columns_df), ignore_index=True)\n",
    "            except:\n",
    "                #hay filas que no tienen el contenido deseado, así que las ignoro cuando fallan\n",
    "                pass\n",
    "                #print(sys.exc_info())\n",
    "\n",
    "# Paso 2: obtener todos los plot de los capítulos de la serie\n",
    "# esto es para tomar el contenido del plot cuando ya estoy en la página del capítulo\n",
    "# como explícitamente quiero haer lenta la iteración de las páginas para asignar el plot, itero a mano por el índice (pendiente)\n",
    "plotsHtml = []\n",
    "plots = []\n",
    "for index, row in chapters_link.iterrows():\n",
    "  chapter_page = requests.get(row[4])\n",
    "  chapter_soup = BeautifulSoup(chapter_page.text, \"html.parser\")\n",
    "  plotsHtml.append(chapter_soup.find('span', attrs={'id':'Plot'}).parent.next_sibling.next_sibling)\n",
    "  plots.append(chapter_soup.find('span', attrs={'id':'Plot'}).parent.next_sibling.next_sibling.getText())\n",
    "  print('guardado plot {}'.format(index))\n",
    "  time.sleep(1)\n",
    "chapters_link['Plot'] = plots\n",
    "chapters_link['PlotHtml'] = plotsHtml\n",
    "print('Fin de carga de plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.598418Z",
     "start_time": "2020-07-12T21:22:16.495177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido del primer capítulo: \n",
      "\n",
      " The USS Enterprise arrives at planet M-113 to provide supplies and medical exams for the only known inhabitants of the planet, Professor Robert Crater (Alfred Ryder) and his wife Nancy (Jeanne Bal), who operate an archaeological research station there. Captain Kirk, Chief Medical Officer Dr. Leonard McCoy, and Crewman Darnell (Michael Zaslow) transport to the surface as Kirk teases McCoy about his affection for Nancy ten years earlier. They arrive in the research station, and each of the three men sees Nancy differently: McCoy as she was when he first met her, Kirk as she should look accounting for her age, and Darnell as an attractive blonde woman who he met on a pleasure planet. When Nancy goes out to fetch her husband, she beckons Darnell to follow her.\n",
      "\n",
      "\n",
      "\n",
      "Contenido de todo el dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.overall</th>\n",
       "      <th>No. inseason</th>\n",
       "      <th>Title</th>\n",
       "      <th>Stardate</th>\n",
       "      <th>Link</th>\n",
       "      <th>Plot</th>\n",
       "      <th>PlotHtml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Man Trap</td>\n",
       "      <td>1513.1</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Man_Trap</td>\n",
       "      <td>The USS Enterprise arrives at planet M-113 to ...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  arrives at plane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Charlie X</td>\n",
       "      <td>1533.6</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Charlie_X</td>\n",
       "      <td>The USS Enterprise meets the merchant vessel A...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  meets the mercha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Where No Man Has Gone Before</td>\n",
       "      <td>1312.4</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Where_No_Man_Has...</td>\n",
       "      <td>The USS Enterprise is on an exploratory missio...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  is on an explora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The Naked Time</td>\n",
       "      <td>1704.2</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Naked_Time</td>\n",
       "      <td>The USS Enterprise under the command of Captai...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  under the comman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The Enemy Within</td>\n",
       "      <td>1672.1</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Enemy_Within...</td>\n",
       "      <td>The USS Enterprise is on a geological explorat...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  is on a geologic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Mudd's Women</td>\n",
       "      <td>1329.8</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mudd%27s_Women</td>\n",
       "      <td>The USS Enterprise under the command of Captai...</td>\n",
       "      <td>[The , [USS , [Enterprise]],  under the comman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  No.overall No. inseason                         Title Stardate  \\\n",
       "0          1            1                  The Man Trap   1513.1   \n",
       "1          2            2                     Charlie X   1533.6   \n",
       "2          3            3  Where No Man Has Gone Before   1312.4   \n",
       "3          4            4                The Naked Time   1704.2   \n",
       "4          5            5              The Enemy Within   1672.1   \n",
       "5          6            6                  Mudd's Women   1329.8   \n",
       "\n",
       "                                                Link  \\\n",
       "0         https://en.wikipedia.org/wiki/The_Man_Trap   \n",
       "1            https://en.wikipedia.org/wiki/Charlie_X   \n",
       "2  https://en.wikipedia.org/wiki/Where_No_Man_Has...   \n",
       "3       https://en.wikipedia.org/wiki/The_Naked_Time   \n",
       "4  https://en.wikipedia.org/wiki/The_Enemy_Within...   \n",
       "5       https://en.wikipedia.org/wiki/Mudd%27s_Women   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  The USS Enterprise arrives at planet M-113 to ...   \n",
       "1  The USS Enterprise meets the merchant vessel A...   \n",
       "2  The USS Enterprise is on an exploratory missio...   \n",
       "3  The USS Enterprise under the command of Captai...   \n",
       "4  The USS Enterprise is on a geological explorat...   \n",
       "5  The USS Enterprise under the command of Captai...   \n",
       "\n",
       "                                            PlotHtml  \n",
       "0  [The , [USS , [Enterprise]],  arrives at plane...  \n",
       "1  [The , [USS , [Enterprise]],  meets the mercha...  \n",
       "2  [The , [USS , [Enterprise]],  is on an explora...  \n",
       "3  [The , [USS , [Enterprise]],  under the comman...  \n",
       "4  [The , [USS , [Enterprise]],  is on a geologic...  \n",
       "5  [The , [USS , [Enterprise]],  under the comman...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#desa - es para poder ver qué tiene un plot y todos los plot concatenados\n",
    "print('Contenido del primer capítulo: \\n\\n', chapters_link.Plot[0])\n",
    "print('\\n\\nContenido de todo el dataframe:')\n",
    "chapters_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comienzo de procesamiento de los capítulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión del primer capítulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T19:47:05.591807Z",
     "start_time": "2020-07-12T19:47:05.525983Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.716102Z",
     "start_time": "2020-07-12T21:22:16.602406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The USS Enterprise arrives at planet M-113 to provide supplies and medical exams for the only known inhabitants of the planet, Professor Robert Crater (Alfred Ryder) and his wife Nancy (Jeanne Bal), who operate an archaeological research station there."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(chapters_link.Plot[0])\n",
    "#separo el capítulo 1 en oraciones e imprimo la primera\n",
    "sentence_spans=list(doc.sents)\n",
    "sentence_spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T19:47:20.463028Z",
     "start_time": "2020-07-12T19:47:20.456047Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.737051Z",
     "start_time": "2020-07-12T21:22:16.721089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The USS Enterprise\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " arrives at planet M-113 to provide supplies and medical exams for the only known inhabitants of the planet, Professor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Robert Crater\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alfred Ryder\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ") and his wife \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nancy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jeanne Bal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "), who operate an archaeological research station there. </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Captain \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kirk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", Chief Medical Officer Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Leonard McCoy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Crewman Darnell\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michael Zaslow\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ") transport to the surface as \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kirk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " teases \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    McCoy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " about his affection for \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nancy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ten years earlier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprimo las entidades (NER; Name Entity Recognition) que Spacy identificó\n",
    "spacy.displacy.render(sentence_spans[0:2], style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que se pudo haber incluido el título, profesión o cargo a la persona (ej. \"Dr. Leonard McCoy\" en lugar de sólo  \"Leonard McCoy\"); para estos casos ver el capítulo \"Expanding named entities\" (https://spacy.io/usage/rule-based-matching#models-rules-ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.773951Z",
     "start_time": "2020-07-12T21:22:16.750013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The USS Enterprise', 0, 18, 'PRODUCT')\n",
      "('Robert Crater', 137, 150, 'PERSON')\n",
      "('Alfred Ryder', 152, 164, 'PERSON')\n",
      "('Nancy', 179, 184, 'PERSON')\n",
      "('Jeanne Bal', 186, 196, 'PERSON')\n",
      "('Kirk', 261, 265, 'PERSON')\n",
      "('Leonard McCoy', 293, 306, 'PERSON')\n",
      "('Crewman Darnell', 312, 327, 'PERSON')\n",
      "('Michael Zaslow', 329, 343, 'PERSON')\n",
      "('Kirk', 373, 377, 'PERSON')\n",
      "('McCoy', 385, 390, 'PERSON')\n",
      "('Nancy', 415, 420, 'PERSON')\n",
      "('ten years earlier', 421, 438, 'DATE')\n",
      "('three', 493, 498, 'CARDINAL')\n",
      "('Nancy', 508, 513, 'PERSON')\n",
      "('McCoy', 527, 532, 'PERSON')\n",
      "('first', 552, 557, 'ORDINAL')\n",
      "('Kirk', 567, 571, 'PERSON')\n",
      "('Darnell', 619, 626, 'PERSON')\n",
      "('Nancy', 695, 700, 'PERSON')\n",
      "('Darnell', 744, 751, 'PERSON')\n"
     ]
    }
   ],
   "source": [
    "# Imprimo la lista de entidades\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(*list(ents), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo: identificar acciones de personas (Persona + Verbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.795888Z",
     "start_time": "2020-07-12T21:22:16.781926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nruler = spacy.pipeline.EntityRuler\\npatterns = [{\"label\": \"PERSON\"},\\n            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\\nruler.add_patterns(patterns)\\nnlp.add_pipe(ruler)\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#backup\n",
    "'''\n",
    "ruler = spacy.pipeline.EntityRuler\n",
    "patterns = [{\"label\": \"PERSON\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:16.855247Z",
     "start_time": "2020-07-12T21:22:16.799877Z"
    }
   },
   "outputs": [],
   "source": [
    "ruler = spacy.pipeline.EntityRuler(nlp2)\n",
    "patterns = [{\"label\": \"PERSON\", \"pattern\": \"Kirk\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp2.add_pipe(ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T11:37:54.077215Z",
     "start_time": "2020-07-13T11:37:54.014614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The USS Enterprise', 0, 18, 'PRODUCT')\n",
      "('Robert Crater', 137, 150, 'PERSON')\n",
      "('Alfred Ryder', 152, 164, 'PERSON')\n",
      "('Nancy', 179, 184, 'PERSON')\n",
      "('Jeanne Bal', 186, 196, 'PERSON')\n",
      "('Kirk', 261, 265, 'PERSON')\n",
      "('Leonard McCoy', 293, 306, 'PERSON')\n",
      "('Crewman Darnell', 312, 327, 'PERSON')\n",
      "('Michael Zaslow', 329, 343, 'PERSON')\n",
      "('Kirk', 373, 377, 'PERSON')\n",
      "('McCoy', 385, 390, 'PERSON')\n",
      "('Nancy', 415, 420, 'PERSON')\n",
      "('ten years earlier', 421, 438, 'DATE')\n",
      "('three', 493, 498, 'CARDINAL')\n",
      "('Nancy', 508, 513, 'PERSON')\n",
      "('McCoy', 527, 532, 'PERSON')\n",
      "('first', 552, 557, 'ORDINAL')\n",
      "('Kirk', 567, 571, 'PERSON')\n",
      "('Darnell', 619, 626, 'PERSON')\n",
      "('Nancy', 695, 700, 'PERSON')\n",
      "('Darnell', 744, 751, 'PERSON')\n",
      "<generator object <genexpr> at 0x0000021FA4472AC8>\n"
     ]
    }
   ],
   "source": [
    "doc2 =  nlp2(chapters_link.Plot[0])\n",
    "#print([(ent.text, ent.label_) for ent in doc2.ents])\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc2.ents]\n",
    "print(*list(ents), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T11:38:18.384712Z",
     "start_time": "2020-07-13T11:38:18.200021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det Xxx True True\n",
      "USS USS PROPN NNP compound XXX True False\n",
      "Enterprise Enterprise PROPN NNP nsubj Xxxxx True False\n",
      "arrives arrive VERB VBZ ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "planet planet NOUN NN pobj xxxx True False\n",
      "M-113 M-113 NOUN NNS dep X-ddd False False\n",
      "to to PART TO aux xx True True\n",
      "provide provide VERB VB advcl xxxx True False\n",
      "supplies supply NOUN NNS dobj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "medical medical ADJ JJ amod xxxx True False\n",
      "exams exam NOUN NNS conj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "the the DET DT det xxx True True\n",
      "only only ADV RB amod xxxx True True\n",
      "known know VERB VBN amod xxxx True False\n",
      "inhabitants inhabitant NOUN NNS pobj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "planet planet NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "Professor Professor PROPN NNP compound Xxxxx True False\n",
      "Robert Robert PROPN NNP compound Xxxxx True False\n",
      "Crater Crater PROPN NNP npadvmod Xxxxx True False\n",
      "( ( PUNCT -LRB- punct ( False False\n",
      "Alfred Alfred PROPN NNP compound Xxxxx True False\n",
      "Ryder Ryder PROPN NNP appos Xxxxx True False\n",
      ") ) PUNCT -RRB- punct ) False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "his -PRON- DET PRP$ poss xxx True True\n",
      "wife wife NOUN NN conj xxxx True False\n",
      "Nancy Nancy PROPN NNP appos Xxxxx True False\n",
      "( ( PUNCT -LRB- punct ( False False\n",
      "Jeanne Jeanne PROPN NNP compound Xxxxx True False\n",
      "Bal Bal PROPN NNP appos Xxx True False\n",
      ") ) PUNCT -RRB- punct ) False False\n",
      ", , PUNCT , punct , False False\n",
      "who who PRON WP nsubj xxx True True\n",
      "operate operate VERB VBP relcl xxxx True False\n",
      "an an DET DT det xx True True\n",
      "archaeological archaeological ADJ JJ amod xxxx True False\n",
      "research research NOUN NN compound xxxx True False\n",
      "station station NOUN NN dobj xxxx True False\n",
      "there there ADV RB advmod xxxx True True\n",
      ". . PUNCT . punct . False False\n",
      "Captain Captain PROPN NNP compound Xxxxx True False\n",
      "Kirk Kirk PROPN NNP ROOT Xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "Chief Chief PROPN NNP compound Xxxxx True False\n",
      "Medical Medical PROPN NNP compound Xxxxx True False\n",
      "Officer Officer PROPN NNP appos Xxxxx True False\n",
      "Dr. Dr. PROPN NNP compound Xx. False False\n",
      "Leonard Leonard PROPN NNP compound Xxxxx True False\n",
      "McCoy McCoy PROPN NNP appos XxXxx True False\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "Crewman Crewman PROPN NNP compound Xxxxx True False\n",
      "Darnell Darnell PROPN NNP nmod Xxxxx True False\n",
      "( ( PUNCT -LRB- punct ( False False\n",
      "Michael Michael PROPN NNP compound Xxxxx True False\n",
      "Zaslow Zaslow PROPN NNP appos Xxxxx True False\n",
      ") ) PUNCT -RRB- punct ) False False\n",
      "transport transport NOUN NN conj xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "surface surface NOUN NN pobj xxxx True False\n",
      "as as SCONJ IN mark xx True True\n",
      "Kirk Kirk PROPN NNP nsubj Xxxx True False\n",
      "teases tease VERB VBZ advcl xxxx True False\n",
      "McCoy McCoy PROPN NNP dobj XxXxx True False\n",
      "about about ADP IN prep xxxx True True\n",
      "his -PRON- DET PRP$ poss xxx True True\n",
      "affection affection NOUN NN pobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "Nancy Nancy PROPN NNP pobj Xxxxx True False\n",
      "ten ten NUM CD nummod xxx True True\n",
      "years year NOUN NNS npadvmod xxxx True False\n",
      "earlier earlier ADV RBR advmod xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "They -PRON- PRON PRP nsubj Xxxx True True\n",
      "arrive arrive VERB VBP ROOT xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "research research NOUN NN compound xxxx True False\n",
      "station station NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "each each DET DT nsubj xxxx True True\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "three three NUM CD nummod xxxx True True\n",
      "men man NOUN NNS pobj xxx True False\n",
      "sees see VERB VBZ conj xxxx True False\n",
      "Nancy Nancy PROPN NNP dobj Xxxxx True False\n",
      "differently differently ADV RB advmod xxxx True False\n",
      ": : PUNCT : punct : False False\n",
      "McCoy McCoy PROPN NNP nsubj XxXxx True False\n",
      "as as SCONJ IN mark xx True True\n",
      "she -PRON- PRON PRP nsubj xxx True True\n",
      "was be AUX VBD advcl xxx True True\n",
      "when when ADV WRB advmod xxxx True True\n",
      "he -PRON- PRON PRP nsubj xx True True\n",
      "first first ADV RB advmod xxxx True True\n",
      "met meet VERB VBD advcl xxx True False\n",
      "her -PRON- PRON PRP dobj xxx True True\n",
      ", , PUNCT , punct , False False\n",
      "Kirk Kirk PROPN NNP appos Xxxx True False\n",
      "as as SCONJ IN mark xx True True\n",
      "she -PRON- PRON PRP nsubj xxx True True\n",
      "should should VERB MD aux xxxx True True\n",
      "look look VERB VB aux xxxx True False\n",
      "accounting account VERB VBG ROOT xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "her -PRON- DET PRP$ poss xxx True True\n",
      "age age NOUN NN pobj xxx True False\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "Darnell Darnell PROPN NNP conj Xxxxx True False\n",
      "as as SCONJ IN prep xx True True\n",
      "an an DET DT det xx True True\n",
      "attractive attractive ADJ JJ amod xxxx True False\n",
      "blonde blonde ADJ JJ amod xxxx True False\n",
      "woman woman NOUN NN pobj xxxx True False\n",
      "who who PRON WP dobj xxx True True\n",
      "he -PRON- PRON PRP nsubj xx True True\n",
      "met meet VERB VBD relcl xxx True False\n",
      "on on ADP IN prep xx True True\n",
      "a a DET DT det x True True\n",
      "pleasure pleasure NOUN NN compound xxxx True False\n",
      "planet planet NOUN NN pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "When when ADV WRB advmod Xxxx True True\n",
      "Nancy Nancy PROPN NNP nsubj Xxxxx True False\n",
      "goes go VERB VBZ advcl xxxx True False\n",
      "out out ADP RP prt xxx True True\n",
      "to to PART TO aux xx True True\n",
      "fetch fetch VERB VB advcl xxxx True False\n",
      "her -PRON- DET PRP$ poss xxx True True\n",
      "husband husband NOUN NN dobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "she -PRON- PRON PRP nsubj xxx True True\n",
      "beckons beckon VERB VBZ ROOT xxxx True False\n",
      "Darnell Darnell PROPN NNP dobj Xxxxx True False\n",
      "to to PART TO aux xx True True\n",
      "follow follow VERB VB xcomp xxxx True False\n",
      "her -PRON- PRON PRP dobj xxx True True\n",
      ". . PUNCT . punct . False False\n",
      "\n",
      " \n",
      " SPACE _SP  \n",
      " False False\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:31:21.922486Z",
     "start_time": "2020-07-12T21:31:21.915757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The USS Enterprise', 'PRODUCT'), ('Robert Crater', 'PERSON'), ('Alfred Ryder', 'PERSON'), ('Nancy', 'PERSON'), ('Jeanne Bal', 'PERSON'), ('Kirk', 'PERSON'), ('Leonard McCoy', 'PERSON'), ('Crewman Darnell', 'PERSON'), ('Michael Zaslow', 'PERSON'), ('Kirk', 'PERSON'), ('McCoy', 'PERSON'), ('Nancy', 'PERSON'), ('ten years earlier', 'DATE'), ('three', 'CARDINAL'), ('Nancy', 'PERSON'), ('McCoy', 'PERSON'), ('first', 'ORDINAL'), ('Kirk', 'PERSON'), ('Darnell', 'PERSON'), ('Nancy', 'PERSON'), ('Darnell', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in doc2.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:30:53.022115Z",
     "start_time": "2020-07-15T00:30:52.514821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kirk', 261, 265, 'PERSON', 7978019779053590073), ('Kirk', 373, 377, 'PERSON', 7978019779053590073), ('Kirk', 567, 571, 'PERSON', 7978019779053590073)]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = English()\n",
    "ruler = EntityRuler(nlp)\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
    "\n",
    "patterns = [{\"label\": \"PERSON\", \"pattern\": \"Kirk\"}]\n",
    "#ruler.add_patterns(patterns)\n",
    "#nlp.add_pipe(ruler)\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(chapters_link.Plot[0])\n",
    "print([(ent.text, ent.start_char, ent.end_char,ent.label_, ent.root.head.lemma) for ent in doc.ents])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T23:06:45.494407Z",
     "start_time": "2020-07-12T23:06:45.488240Z"
    }
   },
   "outputs": [],
   "source": [
    "#ver código en https://spacy.io/usage/rule-based-matching#models-rules-ner\n",
    "\n",
    "from spacy.pipeline import merge_entities\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "def extract_person_orgs(doc):\n",
    "    person_entities = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    for ent in person_entities:\n",
    "        head = ent.root.head\n",
    "        if head.lemma_ == \"work\":\n",
    "            preps = [token for token in head.children if token.dep_ == \"prep\"]\n",
    "            for prep in preps:\n",
    "                orgs = [token for token in prep.children if token.ent_type_ == \"ORG\"]\n",
    "                print({'person': ent, 'orgs': orgs, 'past': head.tag_ == \"VBD\"})\n",
    "    return doc\n",
    "\n",
    "# To make the entities easier to work with, we'll merge them into single tokens\n",
    "nlp.add_pipe(merge_entities)\n",
    "nlp.add_pipe(extract_person_orgs)\n",
    "\n",
    "doc = nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
    "# If you're not in a Jupyter / IPython environment, use displacy.serve\n",
    "displacy.render(doc, options={'fine_grained': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:30:35.162212Z",
     "start_time": "2020-07-15T00:30:35.153617Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "person_action_pattern= [\n",
    "                    {'POS':{'IN':['PROPN']}}]\n",
    "matcher.add(\"ACTION_PTTRN\", None, person_action_pattern)\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T00:30:05.011629Z",
     "start_time": "2020-07-15T00:30:04.875025Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E155] The pipeline needs to include a tagger in order to use Matcher or PhraseMatcher with the attributes POS, TAG, or LEMMA. Try using nlp() instead of nlp.make_doc() or list(nlp.pipe()) instead of list(nlp.tokenizer.pipe()).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-b3ab07941184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mperson_action_pattern\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'LOWER'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'kirk'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"POS\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"ADV\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OP\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ACTION_PTTRN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson_action_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmatch_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E155] The pipeline needs to include a tagger in order to use Matcher or PhraseMatcher with the attributes POS, TAG, or LEMMA. Try using nlp() instead of nlp.make_doc() or list(nlp.pipe()) instead of list(nlp.tokenizer.pipe())."
     ]
    }
   ],
   "source": [
    "\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "person_action_pattern= [{'LOWER':'kirk'}, {\"POS\": \"ADV\", \"OP\": \"*\"}]\n",
    "matcher.add(\"ACTION_PTTRN\", None, person_action_pattern)\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:22.750287Z",
     "start_time": "2020-07-12T21:22:16.957988Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_e6cER-BLoic"
   },
   "outputs": [],
   "source": [
    "#Guardo un plot y todo el texto de la serie para comparar\n",
    "#print(chapters_link['Plot'].str.join('').shape)\n",
    "doc_serie = nlp(chapters_link.Plot.str.cat())\n",
    "doc_serie_merged= nlp(chapters_link.Plot.str.cat())\n",
    "doc_plot1 = nlp(chapters_link['Plot'][0])\n",
    "doc_plot1_merged = nlp(chapters_link['Plot'][0])\n",
    "\n",
    "for entity in doc_serie_merged.ents:\n",
    "    entity.merge()\n",
    "for entity in doc_plot1_merged.ents:\n",
    "    entity.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:22.791178Z",
     "start_time": "2020-07-12T21:22:22.756278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin hacer merge\n",
      "The USS Enterprise (PRODUCT)\n",
      "Robert Crater (PERSON)\n",
      "Alfred Ryder (PERSON)\n",
      "Nancy (PERSON)\n",
      "Jeanne Bal (PERSON)\n",
      "Kirk (PERSON)\n",
      "Leonard McCoy (PERSON)\n",
      "Crewman Darnell (PERSON)\n",
      "Michael Zaslow (PERSON)\n",
      "Kirk (PERSON)\n",
      "McCoy (PERSON)\n",
      "Nancy (PERSON)\n",
      "ten years earlier (DATE)\n",
      "three (CARDINAL)\n",
      "Nancy (PERSON)\n",
      "McCoy (PERSON)\n",
      "first (ORDINAL)\n",
      "Kirk (PERSON)\n",
      "Darnell (PERSON)\n",
      "Nancy (PERSON)\n",
      "Darnell (PERSON)\n",
      "The USS Enterprise (PRODUCT)\n",
      "Antares (PRODUCT)\n",
      "Charlie Evans (PERSON)\n",
      "fourteen years (DATE)\n",
      "Charlie (PERSON)\n",
      "Charlie (PERSON)\n",
      "Alpha V.  Crew (ORG)\n",
      "Antares (ORG)\n",
      "Charlie (PERSON)\n",
      "McCoy (PERSON)\n",
      "Antares (PRODUCT)\n",
      "The USS Enterprise (PRODUCT)\n",
      "the SS Valiant (ORG)\n",
      "Earth (LOC)\n",
      "200 years earlier (DATE)\n",
      "Valiant (PRODUCT)\n",
      "Valiant (PRODUCT)\n",
      "The USS Enterprise (PRODUCT)\n",
      "Kirk (PERSON)\n",
      "Spock (PERSON)\n",
      "Lt (PERSON)\n",
      "Joe Tormolen (PERSON)\n",
      "Tormolen (PERSON)\n",
      "Dr. McCoy (PERSON)\n",
      "McCoy (PERSON)\n",
      "The USS Enterprise (ORG)\n",
      "177 (CARDINAL)\n",
      "Geological Technician Fisher (ORG)\n",
      "Scott (PERSON)\n",
      "Fisher (PERSON)\n",
      "The USS Enterprise (PRODUCT)\n",
      "Kirk (PERSON)\n",
      "Kirk (PERSON)\n",
      "one (CARDINAL)\n",
      "1 (CARDINAL)\n",
      "\n",
      "\n",
      "haciendo merge\n",
      "The USS Enterprise (PRODUCT)\n",
      "Robert Crater (PERSON)\n",
      "Alfred Ryder (PERSON)\n",
      "Nancy (PERSON)\n",
      "Jeanne Bal (PERSON)\n",
      "Kirk (PERSON)\n",
      "Leonard McCoy (PERSON)\n",
      "Crewman Darnell (PERSON)\n",
      "Michael Zaslow (PERSON)\n",
      "Kirk (PERSON)\n",
      "McCoy (PERSON)\n",
      "Nancy (PERSON)\n",
      "ten years earlier (DATE)\n",
      "three (CARDINAL)\n",
      "Nancy (PERSON)\n",
      "McCoy (PERSON)\n",
      "first (ORDINAL)\n",
      "Kirk (PERSON)\n",
      "Darnell (PERSON)\n",
      "Nancy (PERSON)\n",
      "Darnell (PERSON)\n"
     ]
    }
   ],
   "source": [
    "#PENDIENTE: para comparar las entidades antes y después de hacer merge\n",
    "print('sin hacer merge')\n",
    "for entity in doc_serie_merged.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")\n",
    "print('\\n\\nhaciendo merge')\n",
    "for entity in doc_plot1_merged.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Tokens con y sin Merge\n",
    "En esta comparación se nota el efecto de hacer merge y luego hacer la verificación de frecuencia de palabras.\n",
    "Sin hacer Merge, USS y Enterprise son dos tokens distintos cuando se está analizando el Plot.\n",
    "\n",
    "Notar que se encuentran casos donde \"Enterprise\" aparece sin el \"USS\" y por ende aparece como token por separado.\n",
    "\n",
    "### Ver cómo se puede hacer para considerarlos iguales (sinónimos), porque lo mismo pasa con 'Kirk' y 'Captain Kirk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:22.832071Z",
     "start_time": "2020-07-12T21:22:22.800155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "salida \n",
      "[('Enterprise', 10), ('planet', 8), ('ship', 7), ('USS', 6), ('Kirk', 6), ('McCoy', 6), ('\\n', 6), ('Nancy', 4), ('Charlie', 4), (' ', 4)]\n",
      "\n",
      "salida \n",
      "[('planet', 8), ('ship', 7), ('The USS Enterprise', 6), ('Kirk', 6), ('\\n', 6), ('Nancy', 4), ('McCoy', 4), ('Enterprise', 4), ('research', 3), ('Captain', 3)]\n",
      "\n",
      "salida \n",
      "[('Nancy', 4), ('planet', 3), ('Kirk', 3), ('McCoy', 3), ('Darnell', 3), ('research', 2), ('station', 2), ('met', 2), ('USS', 1), ('Enterprise', 1)]\n",
      "\n",
      "salida \n",
      "[('Nancy', 4), ('planet', 3), ('Kirk', 3), ('research', 2), ('station', 2), ('McCoy', 2), ('met', 2), ('Darnell', 2), ('The USS Enterprise', 1), ('arrives', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "docs = [doc_serie, doc_serie_merged, doc_plot1, doc_plot1_merged]\n",
    "for doc_actual in docs:\n",
    "    words = [token.text for token in doc_actual \\\n",
    "            if not token.is_stop and not token.is_punct]\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(10)\n",
    "    print(f\"\\nsalida \\n{common_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de sinónimos o nombres compuestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.037522Z",
     "start_time": "2020-07-12T21:22:22.839051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enterprise vs USS Enterprise 0.7250052656795019\n",
      "Kirk vs Captain Kirk 0.7703250716419314\n",
      "Captain vs Captain Kirk 0.8261662271499984\n",
      "Pol vs Captain Pol 0.6360505226281187\n",
      "Captain vs Captain Pol 0.7397638974070903\n",
      "Captain Kirk vs Captain Pol 0.6690012729041105\n"
     ]
    }
   ],
   "source": [
    "print(f\"Enterprise vs USS Enterprise {nlp('Enterprise').similarity(nlp('USS Enterprise'))}\")\n",
    "print(f\"Kirk vs Captain Kirk {nlp('Kirk').similarity(nlp('Captain Kirk'))}\")\n",
    "print(f\"Captain vs Captain Kirk {nlp('Captain').similarity(nlp('Captain Kirk'))}\")\n",
    "print(f\"Pol vs Captain Pol {nlp('Pol').similarity(nlp('Captain Pol'))}\")\n",
    "print(f\"Captain vs Captain Pol {nlp('Captain').similarity(nlp('Captain Pol'))}\")\n",
    "print(f\"Captain Kirk vs Captain Pol {nlp('Captain Kirk').similarity(nlp('Captain Pol'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.067442Z",
     "start_time": "2020-07-12T21:22:23.046496Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_sKVz2UHJYwZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about: \n"
     ]
    }
   ],
   "source": [
    "doc = doc_serie\n",
    "statements = textacy.extract.semistructured_statements(doc,\"Darnell\")\n",
    "# Prints Results\n",
    "print(\"This text is about: \")\n",
    "for statement in statements:\n",
    "    subject,verb,point = statement\n",
    "    print(f':{point}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.086389Z",
     "start_time": "2020-07-12T21:22:23.072433Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bQLffl34JwOv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts about Kirk :\n"
     ]
    }
   ],
   "source": [
    "#este no anda\n",
    "statements = textacy.extract.semistructured_statements(\n",
    "    doc,\n",
    "    \"Kirk\"\n",
    ")\n",
    "print('Facts about Kirk :')\n",
    "for statement in statements:\n",
    "  subject, verb, fact = statement\n",
    "  print(f\" - {subject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.117307Z",
     "start_time": "2020-07-12T21:22:23.094370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x0000021FA4472DC8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.extract.ngrams(doc, 3, filter_stops=True, filter_punct=True, filter_nums=False, include_pos=None, exclude_pos=None, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.139248Z",
     "start_time": "2020-07-12T21:22:23.122300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact 1: on an exploratory mission to leave the galaxy \n",
      "Fact 2: on a geological exploration of the planet Alpha 177 \n",
      "Fact 3: in pursuit of an unregistered cargo spaceship \n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = textacy.extract.semistructured_statements(doc, 'The USS Enterprise', cue = 'be')\n",
    "for i, x in enumerate(sentences):\n",
    "        subject, verb, fact = x\n",
    "        \n",
    "        print( 'Fact '+str(i+1) +': '+(str(fact))+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.196096Z",
     "start_time": "2020-07-12T21:22:23.151216Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Aj9Xr172NZa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dying planet\n",
      "environmental suit glove\n",
      "only known inhabitants\n",
      "escape attempt\n",
      "sole survivor\n",
      "self-destruct order\n",
      "kirk orders enterprise's shields\n",
      "research team\n",
      "fisher's uniform\n",
      "medical issues\n",
      "attractive blonde woman\n",
      "geological technician fisher\n",
      "research station\n",
      "mr. spock\n",
      "asteroid field\n",
      "landing party\n",
      "ss valiant\n",
      "extrasensory perception\n",
      "dr. leonard mccoy\n",
      "other spacecraft\n",
      "magnetic dust\n",
      "pleasure planet\n",
      "charlie evans\n",
      "joe tormolen\n",
      "medical exams\n",
      "three men\n",
      "planet thasus\n",
      "unregistered cargo spaceship\n",
      "lithium crystal circuits\n",
      "researchers' life support system\n",
      "chief engineer scott\n",
      "strange red liquid\n",
      "alpha v.  crew members\n",
      "fourteen years\n",
      "exploratory mission\n",
      "damaged ship's recorder\n",
      "transporter equipment\n",
      "chief medical officer\n",
      "planet's breakup\n",
      "ship's computer systems\n",
      "control console\n",
      "enterprise's warp engines.[note\n",
      "nearest relatives\n",
      "michael zaslow\n",
      "captain kirk\n",
      "geological exploration\n",
      "alfred ryder\n",
      "earth spaceship\n",
      "uss enterprise\n",
      "ship's library computer\n",
      "jeanne bal\n",
      "transport ship\n",
      "dr. mccoy\n",
      "\"magnetic space storm\n",
      "merchant vessel antares\n",
      "ore samples\n",
      "archaeological research station\n"
     ]
    }
   ],
   "source": [
    "noun_chunks = textacy.extract.noun_chunks(\n",
    "    doc,\n",
    "    min_freq=1\n",
    ")\n",
    "noun_chunks = map(str, noun_chunks)\n",
    "noun_chunks = map(str.lower, noun_chunks)\n",
    "\n",
    "for noun_chunk in set(noun_chunks):\n",
    "  if len(noun_chunk.split(\" \"))>1 :\n",
    "    print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:22:23.210059Z",
     "start_time": "2020-07-12T21:22:23.203077Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xGdLTlCpXT-W"
   },
   "outputs": [],
   "source": [
    "# TO DO LIST\n",
    "# Lista de actores para quitar del análisis del texto\n",
    "# GRAFICAR LÍNEA DE TIEMPO CON CAPITULOS\n",
    "# BAG OF WORDS DE CAPÍTULOS\n",
    "# BAG OF WORDS DE TEMPORADAS\n",
    "# BAG OF WORDS DE SERIE COMPLETA\n",
    "# LISTA DE PERSONAJES POR CAPITULO, TEMPORADA Y SERIE\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StarTrekChapters.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "391.85px",
    "left": "577.433px",
    "right": "20px",
    "top": "3px",
    "width": "770.133px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
